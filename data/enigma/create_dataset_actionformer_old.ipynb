{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenete rgb and flow features into one feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_folder = 'features/flow_anet_resnet200'\n",
    "rgb_folder = 'features/rgb_anet_resnet200'\n",
    "video_list_file = 'resources/video_list.txt'\n",
    "new_features_folder = 'features/features_actionformer'\n",
    "\n",
    "# read the video list\n",
    "with open(video_list_file, 'r') as f:\n",
    "    video_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_feat_vec(flow: np.array, rgb: np.array, filename: str):\n",
    "    \"\"\" save the feature vector to a file\n",
    "\n",
    "    Args:\n",
    "        flow (np.array): Flow feature vector\n",
    "        rgb (np.array): RGB feature vector\n",
    "        filename (str): filename to save the feature vector\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    feat = np.concatenate((flow, rgb), axis=1)\n",
    "    np.save(filename, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenete_video_feat(video_id: str, flow_folder: str, rgb_folder: str, new_features_folder: str):\n",
    "    \"\"\" Concatenates the flow and rgb features for a video and saves the result in a new file.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): video id of the video to process\n",
    "        flow_folder (str): Folder containing the flow features for all videos\n",
    "        rgb_folder (str): Folder containing the rgb features for all videos\n",
    "        new_features_folder (str): Folder where the new features will be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    flow_filename = os.path.join(flow_folder, video_id + '.npy')\n",
    "    rgb_filename = os.path.join(rgb_folder, video_id + '.npy')\n",
    "    one_feat_vec_filename = os.path.join(new_features_folder, video_id + '.npy')\n",
    "    \n",
    "    if not os.path.exists(flow_filename) or not os.path.exists(rgb_filename):\n",
    "        print(f'Missing flow or rgb file for video {video_id}')\n",
    "        exit(1)\n",
    "    \n",
    "    flow = np.load(flow_filename)\n",
    "    rgb = np.load(rgb_filename)\n",
    "    \n",
    "    save_one_feat_vec(flow, rgb, one_feat_vec_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features and create feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(num_processes) as pool:\n",
    "    pool.starmap(concatenete_video_feat, [(video_id, flow_folder, rgb_folder, new_features_folder) for video_id in video_list])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create json dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = [\n",
    "    \"44\",\n",
    "    \"47\",\n",
    "    \"49\",\n",
    "    \"55\",\n",
    "    \"58\",\n",
    "    \"60\",\n",
    "    \"81\",\n",
    "    \"85\",\n",
    "    \"88\",\n",
    "    \"91\",\n",
    "    \"95\",\n",
    "    \"104\",\n",
    "    \"107\",\n",
    "    \"141\",\n",
    "    \"143\",\n",
    "    \"148\",\n",
    "    \"149\",\n",
    "    \"153\",\n",
    "    \"156\",\n",
    "    \"46\",\n",
    "    \"53\",\n",
    "    \"56\",\n",
    "    \"63\",\n",
    "    \"66\",\n",
    "    \"72\",\n",
    "    \"92\",\n",
    "    \"102\",\n",
    "    \"105\",\n",
    "    \"117\",\n",
    "    \"129\",\n",
    "    \"132\",\n",
    "    \"144\",\n",
    "    \"145\",\n",
    "    \"146\",\n",
    "    \"154\",\n",
    "    \"157\",\n",
    "    \"160\"]\n",
    "\n",
    "validation_set = [\n",
    "            \"69\",\n",
    "            \"74\",\n",
    "            \"111\",\n",
    "            \"116\",\n",
    "            \"83\",\n",
    "            \"86\"\n",
    "    ]\n",
    "\n",
    "test_set = [\n",
    "            \"65\",\n",
    "            \"68\",\n",
    "            \"126\",\n",
    "            \"128\",\n",
    "            \"131\",\n",
    "            \"137\",\n",
    "            \"76\",\n",
    "            \"79\",\n",
    "            \"89\",\n",
    "            \"135\"\n",
    "    ]\n",
    "\n",
    "OBJECT_NAMES = [\"Cavi_alimentatore\",\n",
    "                \"Puntale_oscilloscopio\",\n",
    "                \"Clip_di_massa\",\n",
    "                \"Puntale_saldatore\",\n",
    "                \"Avvitatore\",\n",
    "                \"Batteria_avvitatore\",\n",
    "                \"Connettore_Batteria_Avvitatore\",\n",
    "                \"Cacciavite\",\n",
    "                \"Pinza\",\n",
    "                \"Scheda_Alto_Voltaggio\",\n",
    "                \"Scheda_Basso_Voltaggio\",\n",
    "                \"Schermo_Scheda_Basso_Voltaggio\",\n",
    "                \"Registro\"]\n",
    "\n",
    "TR_ACTION_NAME_MAPPING = {0: 'negative',\n",
    "                          1: 'hand_take',\n",
    "                          2: 'hand_release'}\n",
    "\n",
    "ENIGMA_CLASS_NAMES = ['hand_take',\n",
    "                      'hand_release']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list_file = 'resources/video_list.txt'\n",
    "hand_tr_segmantation_gt_folder = 'resources/hand_tr_segmantation_gt'\n",
    "enigma_json_filename = \"enigma_dataset_temp_start.json\"\n",
    "FPS = 30\n",
    "\n",
    "# read the video list\n",
    "with open(video_list_file, 'r') as f:\n",
    "    video_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using boundaries from frame ranges sx, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(video_id: str) -> str:\n",
    "    \"\"\" Get the subset of a video (training, validation or test)\n",
    "\n",
    "    Args:\n",
    "        video_id (str): video id of the video to process\n",
    "\n",
    "    Returns:\n",
    "        str: subset of the video (training, validation or test)\n",
    "    \"\"\"\n",
    "    \n",
    "    if video_id in training_set:\n",
    "        return 'training'\n",
    "    elif video_id in validation_set:\n",
    "        return 'validation'\n",
    "    elif video_id in test_set:\n",
    "        return 'testing'\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_video_duration(df_annotations: pd.DataFrame, video_fps: float) -> float:\n",
    "    \"\"\" Get the duration of a video with a precision of 2 decimal places\n",
    "\n",
    "    Args:\n",
    "        df_annotations (pd.DataFrame): Dataframe containing the annotations of the video with a column 'end_index'\n",
    "        video_fps (float): FPS of the video\n",
    "\n",
    "    Returns:\n",
    "        float: duration of the video with a precision of 2 decimal places\n",
    "    \"\"\"    \n",
    "    \n",
    "    tot_frames = df_annotations.iloc[-1]['end_index'] + 1\n",
    "    return round(tot_frames / video_fps, 2)\n",
    "\n",
    "def get_annotation(segment_series: pd.Series, video_fps : float) -> dict:\n",
    "    \"\"\" Get the annotation of a segment in the format required by the ActionFormer model\n",
    "        \n",
    "    Args:\n",
    "        segment_series (pd.Series): Series containing the annotation of a segment\n",
    "            segment_series = {\n",
    "                \"start_index\": 1200,\n",
    "                \"end_index\": 1800,\n",
    "                \"class\": 1\n",
    "            }\n",
    "        video_fps (float): FPS of the video\n",
    "        \n",
    "    Returns:\n",
    "        dict: annotation of a segment in the format required by the ActionFormer model\n",
    "            annotation = {\n",
    "                \"label\": \"hand_take\",\n",
    "                \"segment\": [ 2.0, 3.0 ],\n",
    "                \"segment(frames)\": [ 60.0, 90.0 ],\n",
    "                \"label_id\": 1\n",
    "            }\n",
    "    \"\"\"    \n",
    "    \n",
    "    # IN OUR CASE WE START FRAMES FROM 0\n",
    "    # IT SHOULD BE OK (https://github.com/happyharrycn/actionformer_release/issues/4#issuecomment-1050008045)\n",
    "    start_index = segment_series['start_index']\n",
    "    end_index = segment_series['end_index']\n",
    "    \n",
    "    # CLASSES STARTS FROM 0 (NEGATIVE CLASS ARE NOT CONSIDERED)\n",
    "    label_id = segment_series['class']\n",
    "    \n",
    "    start_segment = round(start_index / video_fps, 1)\n",
    "    end_segment = round(end_index / video_fps, 1)\n",
    "    \n",
    "    annotation_data = {\n",
    "        \"label\": TR_ACTION_NAME_MAPPING[label_id],\n",
    "        \"segment\": [\n",
    "            start_segment,\n",
    "            end_segment\n",
    "        ],\n",
    "        \"segment(frames)\": [\n",
    "            start_index,\n",
    "            end_index\n",
    "        ],\n",
    "        # WE NEED TO SHIFT THE LABEL_ID BY 1 BECAUSE THE NEGATIVE CLASS IS NOT CONSIDERED\n",
    "        \"label_id\": label_id - 1\n",
    "    }\n",
    "    \n",
    "    return annotation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30\n",
    "\n",
    "enigma_json = dict()\n",
    "enigma_json[\"version\"] = \"ENIGMA\"\n",
    "enigma_json[\"database\"] = dict()\n",
    "\n",
    "for video_id in video_list:\n",
    "    subset = get_subset(video_id)\n",
    "    assert subset is not None, f'Video {video_id} not found in any set'\n",
    "    \n",
    "    # read the ground truth file\n",
    "    hand_tr_segmantation_gt_filename = os.path.join(hand_tr_segmantation_gt_folder, video_id + '.csv')\n",
    "    hand_tr_segmantation_gt = pd.read_csv(hand_tr_segmantation_gt_filename)\n",
    "    \n",
    "    video_duration = get_video_duration(hand_tr_segmantation_gt, FPS)\n",
    "    \n",
    "    # remove the negative class\n",
    "    hand_tr_segmantation_gt = hand_tr_segmantation_gt[hand_tr_segmantation_gt['class'] != 0]\n",
    "    \n",
    "    # create the annotations for the video\n",
    "    video_annotations = [get_annotation(row, FPS) for _,row in hand_tr_segmantation_gt.iterrows()]\n",
    "\n",
    "    video_data_dict = {\n",
    "        \"subset\": subset,\n",
    "        \"duration\": video_duration,\n",
    "        \"fps\": FPS,\n",
    "        \"annotations\": video_annotations\n",
    "    }\n",
    "\n",
    "    enigma_json[\"database\"][str(video_id)] = video_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "with open(enigma_json_filename, 'w') as json_file:\n",
    "    json.dump(enigma_json, json_file, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using small fixed boundaries for contact timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_ACTION_NAME_MAPPING = {0: 'hand_take',\n",
    "                          1: 'hand_release'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(video_id: str) -> str:\n",
    "    \"\"\" Get the subset of a video (training, validation or test)\n",
    "\n",
    "    Args:\n",
    "        video_id (str): video id of the video to process\n",
    "\n",
    "    Returns:\n",
    "        str: subset of the video (training, validation or test)\n",
    "    \"\"\"\n",
    "    \n",
    "    if video_id in training_set:\n",
    "        return 'training'\n",
    "    elif video_id in validation_set:\n",
    "        return 'validation'\n",
    "    elif video_id in test_set:\n",
    "        return 'testing'\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_video_duration(hand_tr_segmantation_gt_filename: str, video_fps: float) -> float:\n",
    "    hand_tr_segmantation_gt = pd.read_csv(hand_tr_segmantation_gt_filename)    \n",
    "    \n",
    "    tot_frames = hand_tr_segmantation_gt.iloc[-1]['end_index'] + 1\n",
    "    return round(tot_frames / video_fps, 2)\n",
    "\n",
    "def get_annotation(segment_series: pd.Series, video_fps : float, video_len : float) -> dict:\n",
    "    \"\"\" Get the annotation of a segment in the format required by the ActionFormer model\n",
    "        \n",
    "    Args:\n",
    "        segment_series (pd.Series): Series containing the annotation of a contact\n",
    "            segment_series = {\n",
    "                \"t-start\": 47.886,\n",
    "                \"class\": 1\n",
    "            }\n",
    "        video_fps (float): FPS of the video\n",
    "        video_len (float): Length of the video\n",
    "        \n",
    "    Returns:\n",
    "        dict: annotation of a segment in the format required by the ActionFormer model\n",
    "            annotation = {\n",
    "                \"label\": \"hand_take\",\n",
    "                \"segment\": [ 2.0, 3.0 ],\n",
    "                \"segment(frames)\": [ 60.0, 90.0 ],\n",
    "                \"label_id\": 1\n",
    "            }\n",
    "    \"\"\"    \n",
    "    \n",
    "    # IN OUR CASE WE START FRAMES FROM 0\n",
    "    # IT SHOULD BE OK (https://github.com/happyharrycn/actionformer_release/issues/4#issuecomment-1050008045)\n",
    "    contact_timestamp = segment_series['t-start']\n",
    "    \n",
    "    # WE CREATE A SEGMENT FROM CONTACT_TIMESTAMP TO THE END OF THE ACTION\n",
    "    start_segment = contact_timestamp\n",
    "    end_segment = segment_series['end_index']\n",
    "    \n",
    "    \n",
    "    # CLASSES STARTS FROM 0 (NEGATIVE CLASS ARE NOT CONSIDERED)\n",
    "    label_id = int(segment_series['class'])\n",
    "    \n",
    "    start_index = int(start_segment - (start_segment % (1/video_fps)))*video_fps\n",
    "    end_index = int(end_segment - (end_segment % (1/video_fps)))*video_fps\n",
    "    \n",
    "    annotation_data = {\n",
    "        \"label\": TR_ACTION_NAME_MAPPING[label_id],\n",
    "        \"segment\": [\n",
    "            start_segment,\n",
    "            end_segment\n",
    "        ],\n",
    "        \"segment(frames)\": [\n",
    "            start_index,\n",
    "            end_index\n",
    "        ],\n",
    "        \"label_id\": label_id\n",
    "    }\n",
    "    \n",
    "    return annotation_data\n",
    "\n",
    "def get_contact_timestamp(filename_csv):\n",
    "    \n",
    "    data = pd.read_csv(filename_csv)\n",
    "    \n",
    "    hand_take_rows = data[data[\"tipo_azione\"] ==\"Hand_Take (mano-oggetto)\"][['timestamp','id_label']]\n",
    "    hand_take_rows['action_type'] = \"hand_take\"\n",
    "    hand_release_rows = data[data[\"tipo_azione\"] ==\"Hand_Release (mano-oggetto)\"][['timestamp','id_label']]\n",
    "    hand_release_rows['action_type'] = \"hand_release\"\n",
    "\n",
    "    actions = pd.concat([hand_take_rows, hand_release_rows])\n",
    "    actions = actions.sort_values(by=['timestamp'])\n",
    "    actions = actions.reset_index(drop=True)\n",
    "    #remove the id from the label e.g. (5.Clip_di_massa) -> Clip_di_massa\n",
    "    actions['id_label'] = [re.sub(\"^[0-9]*.\", '', x) for x in actions['id_label']]\n",
    "    actions['class'] = actions['action_type'].apply(lambda x: ENIGMA_CLASS_NAMES.index(x))\n",
    "    \n",
    "    actions = actions[actions['id_label'].isin(OBJECT_NAMES)]\n",
    "    \n",
    "    actions.drop(columns=['id_label', 'action_type'], inplace=True)\n",
    "    actions.rename(columns={'timestamp': 't-start'}, inplace=True)\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_path = 'resources/enigma_csv'\n",
    "hand_tr_segmantation_gt_folder = 'resources/hand_tr_segmantation_gt'\n",
    "FPS = 30\n",
    "\n",
    "enigma_json = dict()\n",
    "enigma_json[\"version\"] = \"ENIGMA\"\n",
    "enigma_json[\"database\"] = dict()\n",
    "\n",
    "for video_id in video_list:\n",
    "    subset = get_subset(video_id)\n",
    "    assert subset is not None, f'Video {video_id} not found in any set'\n",
    "    \n",
    "    # read the ground truth file\n",
    "    contact_timestamp_gt = get_contact_timestamp(os.path.join(anno_path, video_id + '.csv'))\n",
    "    \n",
    "    # read the ground truth file\n",
    "    hand_tr_segmantation_gt_filename = os.path.join(hand_tr_segmantation_gt_folder, video_id + '.csv')\n",
    "    video_duration = get_video_duration(hand_tr_segmantation_gt_filename, FPS)\n",
    "    \n",
    "    # create the annotations for the video\n",
    "    video_annotations = [get_annotation(row, FPS, video_duration) for _,row in contact_timestamp_gt.iterrows()]\n",
    "\n",
    "    video_data_dict = {\n",
    "        \"subset\": subset,\n",
    "        \"duration\": video_duration,\n",
    "        \"fps\": FPS,\n",
    "        \"annotations\": video_annotations\n",
    "    }\n",
    "\n",
    "    enigma_json[\"database\"][str(video_id)] = video_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "with open(enigma_json_filename, 'w') as json_file:\n",
    "    json.dump(enigma_json, json_file, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_index  end_index  class\n",
      "56        34084      34099      2\n",
      "57        34100      34167      1\n",
      "58        34168      34927      0\n",
      "59        34928      34980      1\n",
      "60        34981      38283      0\n",
      "38284\n"
     ]
    }
   ],
   "source": [
    "video_id = '44'\n",
    "\n",
    "hand_tr_segmantation_gt_filename = os.path.join(hand_tr_segmantation_gt_folder, video_id + '.csv')\n",
    "hand_tr_segmantation_gt = pd.read_csv(hand_tr_segmantation_gt_filename)\n",
    "\n",
    "print(hand_tr_segmantation_gt.tail())\n",
    "\n",
    "tot_frames = hand_tr_segmantation_gt.iloc[-1]['end_index'] + 1\n",
    "print(tot_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
